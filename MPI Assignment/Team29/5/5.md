# **Question 5: Parallel Matrix Chain Multiplication Problem**

## **Objective:**
The task is to find the optimal order of multiplying a sequence of matrices to minimize the total number of scalar multiplications. This problem is solved using dynamic programming and parallelized using MPI.

## **Approach:**

### 1. **Input Handling:**
- The root process (rank 0) reads the number of matrices \( N \) and their dimensions. This information is then broadcasted to all processes so that every process has the data needed for computation.

### 2. **Scattering Dimensions:**
- The matrix dimensions are broadcasted to all participating processes using `MPI_Bcast`. This ensures that every process has the complete dimensions array for the matrix chain multiplication problem.

### 3. **Dynamic Programming with Parallelization:**
- **Cost Matrix Initialization:** A 2D cost matrix is used to store the minimum number of scalar multiplications required for different matrix chains.
- **Parallel Calculation:** Each process computes a portion of the cost matrix in parallel, which reduces the overall computation time.
- **Synchronization:** Processes are synchronized using `MPI_Barrier` after each stage of computation to ensure all processes have completed their work.
- **Broadcast Updates:** Updated rows of the cost matrix are broadcasted to all processes, allowing for accurate subsequent computations.

### 4. **Final Output:**
- The root process (rank 0) gathers the results and outputs the minimum number of scalar multiplications required for the entire matrix chain.

## **MPI Functions Used:**
- `MPI_Init`, `MPI_Finalize`: Initialize and finalize the MPI environment.
- `MPI_Comm_rank`, `MPI_Comm_size`: Determine the rank of the process and the total number of processes.
- `MPI_Bcast`: Broadcast the dimensions array and cost matrix rows to all processes.
- `MPI_Barrier`: Synchronize processes after each computation phase.

### **Complexity Analysis:**

#### **1. Time Complexity:**
- The time complexity of the dynamic programming approach in a parallel environment is approximately \(O\left(\frac{N^3}{p}\right)\), where \( p \) is the number of processes.

#### **2. Message Complexity:**
- The message complexity involves broadcasting and synchronization steps, resulting in a complexity of \(O(N^2 \log p)\).

#### **3. Space Requirements:**
- **Per Process:** Each process requires \(O(N^2)\) space for storing its portion of the cost matrix and the full dimensions array.
- **Total Space:** The total space required across all processes remains \(O(N^2)\).

## **Results:**
- The program successfully computes the optimal matrix multiplication order in a distributed manner. The efficiency improves with the number of processes, particularly for large matrix chains.
